{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Questions\n",
    "\n",
    "This version of the exercises uses the [Air Quality](https://archive.ics.uci.edu/ml/datasets/Air+Quality#) dataset includes observations of various air quality and pollutant indicators. It's commonly used in regression model tutorials as it has several predictors with linear relationships to multiple pollutants. We will use it here as a simple modeling example that will allow us to focus on model metrics and evaluation procedures.\n",
    "\n",
    "The dataset includes the following information:\n",
    "- date/time indicators\n",
    "- weather indicators\n",
    "- several pollutants of potential interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"air_quality.csv\")\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset\n",
    "\n",
    "Take a few minutes to explore the dataset. How many potential predictors are there for a model predicting `benzene` (a compound that reacts with other chemicals to create smog) quantities in the air?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation matrix to identify potential predictors\n",
    "df_corr = df.corr().round(2)\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a threshold for correlation values; optional\n",
    "y_corr = df_corr[\"benzene\"][np.absolute(df_corr[\"benzene\"])>0.5]\n",
    "y_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the shape of relationships \n",
    "sns.pairplot(df[y_corr.index]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for model\n",
    "\n",
    "1. Compare at least two models using scikit-learn. You can view the list of available linear models with scikit-learn [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model). Use at least 2 metrics from scikit-learn's regression evaluation metrics [here](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up X to only include selected column names\n",
    "X = df[y_corr.index]\n",
    "\n",
    "# Fill missing data with 0; you can change this if you choose\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Drop outcome variable\n",
    "X = X.drop(\"benzene\", axis = \"columns\")\n",
    "\n",
    "# Get y\n",
    "y = df[\"benzene\"]\n",
    "\n",
    "## Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9)\n",
    "\n",
    "## Standardize the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Model\n",
    "\n",
    "Fit the first model and evaluate the model metrics. Compare it to at least one other model and select one going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions based on the test set \n",
    "y_preds = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{lr} training set r2 score: {lr.score(X_train, y_train).round(2)}\")\n",
    "print(f\"{lr} test set r2 score: {r2_score(y_test, y_preds).round(2)}\")\n",
    "# Choose another metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to another model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling for Explanation\n",
    "\n",
    "Modeling for explanation generally requires more detailed information on individual predictors than scikit-learn provides. In order to model for explanation, we will leverage the `statsmodels` library to explore our model further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train, x_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary(xname = [\"const\"] + list(X.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explore the `statsmodels` OLS regression summary above. Are there features that are _not_ statistically significant predictors of `benzene` in this model? Try removing them (drop them and recreate the training/test set) and re-evaluate the strength and directionality of the t-values. If not, consider which predictors might be more _actionable_ to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The local government is seeking to identify two or three actions to take to reduce smog in the city related to benzene content in the atmosphere. Generate (1) a summary of results, (2) a series of visualizations of key predictors, and (3) an overall recommendations on what environmental issues to pursue a program for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
