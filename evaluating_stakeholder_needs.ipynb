{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Statistical Models for Stakeholder Needs\n",
    "\n",
    "This tutorial will focus on methods for evaluating, interpreting, and reporting on the results of models based on the needs of stakeholders. \n",
    "\n",
    "Throughout this tutorial, we will cover the following topics:\n",
    "- overview of model evaluation\n",
    "  - commonly used model metrics for regressors and classifiers\n",
    "  - model metrics for individual predictors/features\n",
    "- modeling purposes\n",
    "  - models for explanation\n",
    "  - models for prediction\n",
    "- identifying and understanding stakeholder needs\n",
    "  - understanding model purpose based on questions\n",
    "  - selecting and evaluating models \n",
    "  - making concrete recommendations\n",
    "  \n",
    "This tutorial notebook will use the `diabetes` dataset available in scikit-learn's `datasets` module. Two additional notebooks are available for you to follow along using the dataset that's of most interest to you. Please use that notebook for the exercise portion of the tutorial, and use this notebook as a reference.\n",
    "\n",
    "Let's start by importing `numpy`, `pandas`, `seaborn`, and the `diabetes` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Import diabetes dataset from sklearn\n",
    "from sklearn import datasets\n",
    "db = datasets.load_diabetes(as_frame = True)\n",
    "\n",
    "# Extract the dataset as a pandas dataframe\n",
    "df = db.frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `diabetes` dataset has 442 data points with 10 potential predictors of the target -- a continuous measure of the progression of the disease. This information is available in the `dataset.DESCR` description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset info\n",
    "print(db.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Relationships between Variables\n",
    "\n",
    "For this tutorial, we will primarily use linear models for ease of explanation and exploration of relationships between predictors. In order to start exploring linear relationships, we will generate a correlation matrix of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation matrix to identify potential predictors\n",
    "df_corr = df.corr().round(2)\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we start by looking at correlation strengths with the `target`, we see that a number of moderate to strong correlation strengths. \n",
    "\n",
    "For the purpose of this tutorial, we will create a subset of features that are at least moderately (commonly defined as `r>=0.3`) correlated with the target. I strongly recommend you spend additional time on your own fine tuning linear models to ensure the shape of relationships is properly represented in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a threshold for correlation values; optional\n",
    "target_corr = df_corr[\"target\"][(np.absolute(df_corr[\"target\"])>0.3)]\n",
    "target_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily explore visual relationships between variables using seaborn's `pairplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the shape of relationships \n",
    "sns.pairplot(df[target_corr.index]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Model\n",
    "\n",
    "We'll fit a linear model and evaluate it using the $r^2$ score and mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up X to only include selected column names\n",
    "X = df[target_corr.index]\n",
    "\n",
    "# Fill missing data with 0; you can change this if you choose\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Drop outcome variable\n",
    "X = X.drop(\"target\", axis = \"columns\")\n",
    "\n",
    "# Get y\n",
    "y = df[\"target\"]\n",
    "\n",
    "## Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "\n",
    "## Standardize the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions based on the test set \n",
    "y_preds = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation metrics\n",
    "print(f\"{lr} training set r2 score: {lr.score(X_train, y_train).round(2)}\")\n",
    "print(f\"{lr} test set r2 score: {r2_score(y_test, y_preds).round(2)}\")\n",
    "\n",
    "print(f\"{lr} test set mean squared error: {mean_squared_error(y_test, y_preds).round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Purposes\n",
    "\n",
    "Chester Ismay and Albert Kim's book, [Modern Dive](https://moderndive.com/5-regression.html), provides an excellent synopsis of the two broad purposes of modeling. To summarize, a model is typically fit for one of two purposes: explanation, and prediction.\n",
    "\n",
    "**Models for explanation** typically involve more detailed exploration of the significance/importance of individual predictors than scikit-learn makes easily available. We'll use `statsmodels` for that purpose.\n",
    "\n",
    "**Models for prediction** focus on the predictive strength of the overall model and future predicted values of `y`. In this case, you generally do not need to understand the detailed relationships between individual predictors and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A constant needs to be added to your model for direct comparison with the scikit-learn output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train, x_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a constant removes the predictor names, so you need to re-add them as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary(xname = [\"const\"] + list(X.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two of the predictors (s4 = thyroid hormone, and s6 = blood glucose level) have very low `t` values, and non-significant `p` values. \n",
    "\n",
    "In combination with the other predictors in the model, they do not add new value to the model and can likely be dropped.\n",
    "\n",
    "## Leveraging this model for different purposes\n",
    "- Modeling for explanation - some questions you might ask of this data include:\n",
    "  - What single best recommendation should be made to diabetes patients to improve their outcomes?\n",
    "  - A series of drugs to improve blood glucose levels will be distributed for free to diabetic patients. Will it be effective?\n",
    "\n",
    "\n",
    "- Modeling for prediction: \n",
    "  - What is the expected disease progression of diabetes for a series of 1,000 newly diagnosed patients?\n",
    "  \n",
    "When modeling for explanation, we would likely return and perform a more sophisticated modeling of individual predictors. We will start by dropping the two predictors that are not significant and re-evaluating the model. We might also want to reduce the model threshold and consider the value of other predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling for explanation steps: fine tune the model\n",
    "target_corr = df_corr[\"target\"][(np.absolute(df_corr[\"target\"])>0.2)]\n",
    "X = df[target_corr.index]\n",
    "\n",
    "# Fill missing data with 0; you can change this if you choose\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Drop outcome variable and extraneous predictors\n",
    "X = X.drop([\"target\", \"s4\", \"s6\"], axis = \"columns\")\n",
    "\n",
    "## Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "\n",
    "## Standardize the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "x_train = sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train, x_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary(xname = [\"const\"] + list(X.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Stakeholder Needs\n",
    "\n",
    "### Explanation\n",
    "#### Model Selection\n",
    "In general, when using a statistical model to explain the impact of a process, you will be able to most comprehensively report on a model that provides the _strength_ and _directionality_ of the relationship between individual coefficients and the target variable. In short:\n",
    "- start with linear models, or other models that allow for comprehensive reporting on relationships. The [statsmodels documentation](https://www.statsmodels.org/dev/index.html) includes many options to explore\n",
    "- optimize for the _strength_ and _shape_ of relationships with key predictors and the outcome variable\n",
    "\n",
    "#### Reporting on Results\n",
    "When providing detailed explanations of a model, you will likely be providing a written summary of conclusions of the overall model that is only a partial representation of the entire set of results. I strongly recommend your explanation include the following summary:\n",
    "- a list of all predictors included in the model\n",
    "- the overall R-squared (amount of variation predicted overall)\n",
    "- the relative _strength_ and _direction_ of the relationship between key actionable predictors and y\n",
    "- a comparison of the _strength_ of the relationship between key actionable predictors and other predictors\n",
    "- a visual representation of the relationship between x and y (e.g., a scatterplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"s3\", y=\"target\", data=df, marker=\"+\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
